# -*- coding: utf-8 -*-
"""Sales Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t030B9dNNXuopCou6W7pnIA23Zb9Jl76
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from scipy.stats import mode

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout

#dataset
train_df = pd.read_csv("Train.csv")
test_df = pd.read_csv("Test.csv")

train_df.head(10)

train_df.info()

for cols in train_df.columns:
    print(cols, train_df[cols].nunique())

train_df.describe()

train_df['Item_Identifier']

corr = train_df[['Item_Weight', 'Item_Visibility', 'Item_MRP','Item_Outlet_Sales']].corr(method='pearson')
g = sns.heatmap(corr, cmap="coolwarm", vmax=1, square=True, annot=True, fmt='.2f')
g.set_xticklabels(g.get_xticklabels(), rotation=45)
g.set_yticklabels(g.get_yticklabels(), rotation=0)

sns.pairplot(data=train_df, hue='Outlet_Type', diag_kind='hist', palette="Set1")

relations('Outlet_Identifier')

train_df.pivot_table(values='Outlet_Type', columns='Outlet_Identifier', aggfunc=lambda x:x.mode())

train_df.pivot_table(values='Outlet_Type', columns='Outlet_Size',aggfunc=lambda x:x.mode())

relations('Outlet_Establishment_Year')

relations('Outlet_Location_Type')

train_df.pivot_table(values='Outlet_Type', columns='Outlet_Location_Type', aggfunc=lambda x:x.mode())

relations('Outlet_Type')
relations('Outlet_Size')
relations('Item_Fat_Content')
relations('Item_Type')
sns.scatterplot(data=train_df, x='Item_Weight', y='Item_Outlet_Sales', alpha=0.3)

sns.scatterplot(data=train_df, x='Item_Visibility', y='Item_Outlet_Sales', alpha=0.3)

train_df['source']='train'
test_df['source']='test'
data = pd.concat([train_df,test_df], ignore_index = True)
print(train_df.shape, test_df.shape, data.shape)

data.info()

data['Item_Fat_Content'] = data['Item_Fat_Content'].replace(['low fat', 'LF'], 'Low Fat')
data['Item_Fat_Content'] = data['Item_Fat_Content'].replace('reg', 'Regular')

for i in range(len(data)):
    if pd.isna(data.loc[i,'Outlet_Size']):
        if (data.loc[i,'Outlet_Type']=='Grocery Store') or (data.loc[i,'Outlet_Type']=='Supermarket Type1') :
            data.loc[i, 'Outlet_Size'] = 'Small'
        elif (data.loc[i,'Outlet_Type']=='Supermarket Type2') or (data.loc[i,'Outlet_Type']=='Supermarket Type3') :
            data.loc[i, 'Outlet_Size'] = 'Medium'
data['Item_Type_Category'] = data['Item_Identifier'].apply(lambda x: x[0:2])
data['Item_Type_Category'] = data['Item_Type_Category'].map({'FD':'Food', 'NC':'Non-Consumable', 'DR':'Drinks'})
data['Item_Type_Category'].value_counts()

data.loc[data['Item_Type_Category']=='Non-Consumable','Item_Fat_Content'] = "Non-Edible"
Item_Type_Mean = data.pivot_table(columns='Item_Type', values='Item_Weight', aggfunc=lambda x:x.mean())

for i in range(len(data)):
    if pd.isna(data.loc[i, 'Item_Weight']):
        item = data.loc[i, 'Item_Type']
        data.at[i, 'Item_Weight'] = Item_Type_Mean[item]
Item_Visibility_Mean = data[['Item_Type_Category', 'Item_Visibility']].groupby(['Item_Type_Category'], as_index=False).mean()
Item_Visibility_Mean.columns

for i in range(len(data)):
    if data.loc[i, 'Item_Visibility']==0:
        cat =  data.loc[i, 'Item_Type_Category']
        m = Item_Visibility_Mean.loc[Item_Visibility_Mean['Item_Type_Category'] == cat]['Item_Visibility']
        data.at[i, 'Item_Visibility'] = m
data['Operation_Years'] = 2013-data['Outlet_Establishment_Year']
data=data.drop(['Item_Type', 'Outlet_Establishment_Year'], axis=1)
lb=LabelEncoder()
data['Outlet']=lb.fit_transform(data['Outlet_Identifier'])
var=['Item_Fat_Content','Outlet_Location_Type','Outlet_Type','Outlet_Size','Item_Type_Category']
lb=LabelEncoder()
for item in var:
    data[item]=lb.fit_transform(data[item])
data = pd.get_dummies(data, columns=['Item_Fat_Content','Outlet_Location_Type','Outlet_Type','Outlet_Size','Item_Type_Category'])
data.head(10)

train = data.loc[data['source']=='train']
test = data.loc[data['source']=='test']
train = train.drop(['source'], axis=1)
test = test.drop(['source'], axis=1)
train.columns, test.columns, train.shape, test.shape

data_temp = train.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1)
x_train = train.drop(['Item_Outlet_Sales', 'Item_Identifier', 'Outlet_Identifier'], axis=1)
y_train = train['Item_Outlet_Sales']
x_test = test.drop(['Item_Outlet_Sales','Item_Identifier', 'Outlet_Identifier'], axis=1)

x_train.shape, y_train.shape, x_test.shape
((8523, 21), (8523,), (5681, 21))
x_train.columns, x_test.columns

scaler = MinMaxScaler(feature_range=(0,1))
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.fit_transform(x_test)

#RNN model
model_RNN = Sequential()
model_RNN.add(LSTM(units=128, return_sequences=True, input_shape=(x_train_scaled.shape[1], 1)))
model_RNN.add(Dropout(0.2))
model_RNN.add(LSTM(units=64, return_sequences=True))
model_RNN.add(Dropout(0.2))
model_RNN.add(LSTM(units=32, return_sequences=False))
model_RNN.add(Dropout(0.2))
model_RNN.add(Dense(units=1))

model_RNN.compile(optimizer='adam', loss='mean_squared_error')

#  Linear Regression model
model_LinReg = LinearRegression()

#ridge regression
model_RidgeReg = Ridge()

# Random Forest Regression model
model_RFReg = RandomForestRegressor(random_state=42)

# Train Models
x_train_scaled, x_val_scaled, y_train, y_val = train_test_split(x_train_scaled, y_train, test_size=0.2, random_state=42)

model_RNN.fit(x_train_scaled, y_train, validation_data=(x_val_scaled, y_val), epochs=100, verbose=1)
model_LinReg.fit(x_train_scaled, y_train)
model_RidgeReg.fit(x_train_scaled, y_train)
model_RFReg.fit(x_train_scaled, y_train)

# Evaluate Models
score_RNN = model_RNN.evaluate(x_val_scaled, y_val)
score_LinReg = model_LinReg.score(x_val_scaled, y_val)
score_RidgeReg = model_RidgeReg.score(x_val_scaled, y_val)
score_RFReg = model_RFReg.score(x_val_scaled, y_val)

print("\nModel Scores:\n")
print("RNN:", score_RNN)
print("Linear Regression:", score_LinReg)
print("Ridge Regression:", score_RidgeReg)
print("Random Forest Regression:", score_RFReg)

import joblib

# Save the trained model
joblib.dump(model_RNN, 'model_RNN.pkl')
joblib.dump(model_LinReg, 'model_LinReg.pkl')
joblib.dump(model_RidgeReg, 'model_RidgeReg.pkl')
joblib.dump(model_RFReg, 'model_RFReg.pkl')

# Load the saved model
loaded_model = joblib.load('model_RNN.pkl')

scaler = MinMaxScaler(feature_range=(0,1))
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

# Save the MinMaxScaler model
joblib.dump(scaler, 'min_max_scaler.pkl')

SCALER = joblib.load('min_max_scaler.pkl')

